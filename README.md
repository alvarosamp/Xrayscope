# Data Review

Projeto MLOps com fluxo CD4ML completo incluindo aplica√ß√£o web com suporte de IA, deploy automatizado local e em cloud (AWS) usando IaC

## üìã Vis√£o Geral

Este projeto implementa uma arquitetura de MLOps completa incluindo:

- **MLflow**: Tracking de experimentos e registro de modelos
- **Webapp**: Interface web para predi√ß√µes
- **Jupyter Notebook**: Ambiente para treinamento de modelos
- **Infraestrutura local**: Deploy automatizado com Docker Compose
- **Infraestrutura cloud AWS**: Deploy automatizado com Terraform
- **Containeriza√ß√£o**: Docker para todos os componentes

## üèóÔ∏è Arquitetura

### Local
- **MLflow**: http://localhost:5000
- **Webapp**: http://localhost:8080
- **MinIO**: http://localhost:9000 (S3 local)
- **Jupyter**: Execu√ß√£o local

### Cloud (AWS)
- **MLflow**: http://mlflow.hm-mlflow.local
- **Webapp**: http://app.hm-mlflow.local
- **S3**: Buckets AWS para dados e artefatos
- **ECS Fargate**: Containers gerenciados
- **SageMaker**: Notebooks na nuvem
- **ALB**: Load balancer para roteamento

### Base de dados
A base de dados utilizada no projeto √© a Chest X-Ray Images (Pneumonia), que cont√©m milhares de imagens de raios-X de t√≥rax classificadas como normais ou com pneumonia, servindo para treinar e avaliar modelos de diagn√≥stico assistido por IA.
Dispon√≠vel em: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia

## üöÄ Execu√ß√£o Local

### Pr√©-requisitos
- Docker e Docker Compose
##
sudo apt-get remove -y docker docker-engine docker.io containerd runc
sudo apt-get update
sudo apt-get install -y ca-certificates curl gnupg lsb-release
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | \
  sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg

echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \
  https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt-get update
sudo apt-get install -y docker-ce docker-ce-cli containerd.io \
    docker-buildx-plugin docker-compose-plugin
#(Opcional) Executar Docker sem sudo
sudo groupadd -f docker
sudo usermod -aG docker $USER


- Python 3.8+

### Passos

1. **Baixe o projeto e configure o ambiente:**
```bash
cd hm-mlflow
cp .env.example .env
```

2. **Inicie os servi√ßos:**
```bash
docker compose up --build
```

3. **Acesse os servi√ßos:**
- MLflow UI: http://localhost:5000
- Webapp: http://localhost:5001
- MinIO: http://localhost:9000

4. **Crie uma venv, instale as depend√™ncias e execute o notebook de treinamento:**
```bash
cd jupyter
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
jupyter lab
```
- Mantenha `PROFILE = "local"` no notebook
- N√£o altere nenhuma outra vari√°vel, o notebook √© programado para ser executado localmente por padr√£o
- Execute todas as c√©lulas e analise os logs sobre o sucesso do registro da nova vers√£o

## ‚òÅÔ∏è Execu√ß√£o na Nuvem (AWS) - 
### ATEN√á√ÉO - A implementa√ß√£o em n√∫vem gera custos. Rode-a apenas se tiver plena consci√™ncia disso.

### Pr√©-requisitos

- [Terraform](https://learn.hashicorp.com/tutorials/terraform/install-cli)
```bash
# Atualiza pacotes
sudo apt-get update && sudo apt-get install -y gnupg software-properties-common
# Adiciona a chave GPG da HashiCorp
wget -O- https://apt.releases.hashicorp.com/gpg | gpg --dearmor | sudo tee /usr/share/keyrings/hashicorp-archive-keyring.gpg
# Adiciona o reposit√≥rio oficial
echo "deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] \
https://apt.releases.hashicorp.com $(lsb_release -cs) main" \
| sudo tee /etc/apt/sources.list.d/hashicorp.list
# Atualiza novamente
sudo apt-get update
# Instala Terraform
sudo apt-get install terraform
```


- [AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html)
```bash
# Instale unzip se necess√°rio
sudo apt-get update && sudo apt-get install -y unzip
# Baixar o pacote oficial
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
# Descompactar
unzip awscliv2.zip
# Instalar
sudo ./aws/install
```

- Credenciais AWS configuradas
```bash
aws configure

aws sts get-caller-identity
```

### Passo 1: Deploy da Infraestrutura

1. **Inicialize o Terraform:**
```bash
cd infra
terraform init
```

2. **Crie os reposit√≥rios ECR:**
```bash
terraform apply -target=aws_ecr_repository.mlflow -target=aws_ecr_repository.webapp -target=aws_ecr_repository.model
```

3. **Obtenha seu AWS Account ID e fa√ßa login no ECR:**
```bash
# Obter o Account ID
AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
echo "Seu AWS Account ID: $AWS_ACCOUNT_ID"

# Login no ECR
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com
```

4. **Build e push das imagens:**
```bash
## Na raiz do projeto
/hm-mlflow

# Definir vari√°vel com o Account ID (se n√£o definida no passo anterior)
AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
ECR_URI="$AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com"

# MLflow
docker build -t mlflow-image -f mlflow/Dockerfile-mlflow mlflow/
docker tag mlflow-image:latest $ECR_URI/hm-mlflow/mlflow:latest
docker push $ECR_URI/hm-mlflow/mlflow:latest

# Webapp
docker build -t webapp-image -f webapp/Dockerfile-webapp webapp/
docker tag webapp-image:latest $ECR_URI/hm-mlflow/webapp:latest
docker push $ECR_URI/hm-mlflow/webapp:latest

# Model
docker build -t model-image -f model/Dockerfile-model model/
docker tag model-image:latest $ECR_URI/hm-mlflow/model:latest
docker push $ECR_URI/hm-mlflow/model:latest
```

5. **Atualize as vari√°veis do Terraform:**
```bash
# Substitua <AWS_ACCOUNT_ID> pelo seu Account ID real no variables.tf
AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
sed -i "s/<AWS_ACCOUNT_ID>/$AWS_ACCOUNT_ID/g" infra/variables.tf
```
Ou edite manualmente `infra/variables.tf` substituindo `<AWS_ACCOUNT_ID>` pelo seu Account ID nas vari√°veis:
- `mlflow_image_uri`
- `webapp_image_uri` 
- `model_image_uri`

6. **Deploy completo:**
```bash
cd infra
terraform plan
terraform apply
```

### Passo 2: Configurar DNS Local

1. **Obtenha o IP do ALB:**
```bash
nslookup <ALB_DNS_NAME>
```
**Essa informa√ß√£o pode ser obtida com:**
```bash
cd infra && teraform output
```

2. **Adicione ao arquivo hosts:**
- **Tecla de atalho para o Executar**: win+R
- **Windows**: `C:\Windows\System32\drivers\etc\hosts`
- **Linux/macOS**: `/etc/hosts`
**Precisa ter privil√©gio de administrador para modificar o arquivo**
- **No Windows, ap√≥s abrir o Executar, digite notepad e pressione ctrl+shift+enter**


```
<ALB_IP> mlflow.hm-mlflow.local app.hm-mlflow.local
```

### Passo 3: Executar Treinamento via ECS

```bash
# Obter valores do Terraform
SUBNET_ID=$(terraform output -json public_subnet_ids | jq -r '.[0]')
SG_ID=$(terraform output -raw ecs_security_group_id)

# Executar task
aws ecs run-task \
  --cluster hm-mlflow-cluster \
  --task-definition hm-mlflow-model-training \
  --launch-type FARGATE \
  --network-configuration "awsvpcConfiguration={subnets=[$SUBNET_ID],securityGroups=[$SG_ID],assignPublicIp=ENABLED}" \
  --region us-east-1
```

### Verifique o acesso
Acesse no seu navegador:
- **MLflow**: http://mlflow.hm-mlflow.local
- **Webapp**: http://app.hm-mlflow.local


### Aten√ß√£o
# Caso as informa√ß√µes do modelo vers√£o 1 estiverem aparecendo no rodap√©, mas a previs√£o n√£o estiver sendo feita, pode ter vencido o tempo de espera da webapp pra carregar o modelo. Ap√≥s a finaliza√ß√£o da task anterior de treinamento, rode o comando a seguir para atualizar o servi√ßo de webapp que ele conseguir√° fazer previs√µes
```bash
aws ecs update-service \
  --cluster hm-mlflow-cluster \
  --service hm-mlflow-webapp-service \
  --force-new-deployment \
  --region us-east-1
```

### Passo 4: Executar Treinamento no SageMaker

1. **Acesse o SageMaker:**
- Console AWS ‚Üí SageMaker Studio ‚Üí Notebook instances
- Abra `hm-mlflow-notebook`

2. **Fa√ßa upload do notebook:**
- Upload `jupyter/training_notebook.ipynb`

3. **Obtenha os valores necess√°rios localmente:**
```bash
# No seu ambiente local, na pasta infra
cd infra
echo "ALB_DNS_NAME: $(terraform output -raw alb_dns_name)"
echo "DATASOURCE_BUCKET_NAME: $(terraform output -raw datasource_bucket_name)"
```

4. **Configure e execute no SageMaker:**
- Altere `PROFILE = "cloud"` na segunda c√©lula
- Preencha as vari√°veis `ALB_DNS_NAME` e `DATASOURCE_BUCKET_NAME` com os valores obtidos no passo anterior
- Execute todas as c√©lulas

5. **Destrui√ß√£o da infraestrutura na AWS (cloud)**
# Ap√≥s finalizar seus trabalhos e validar todo funcionamento, voc√™ pode, quando quiser, remover TODA infraestrutura para n√£o gerar gastos adicionais
```bash
# No seu ambiente local, na pasta infra
cd infra
terraform destroy
```

### ATEN√á√ÉO
# A n√£o remo√ß√£o dos recursos da AWS geram custos permanentes at√© que voc√™ os remova. Caso voc√™ esteja apenas utilizando para estudo, n√£o esque√ßa de limpar o ambiente para n√£o sofrer cobran√ßas indesejadas.

## üìä Monitoramento

### Logs AWS
```bash
# Logs do MLflow
aws logs get-log-events --log-group-name "/ecs/hm-mlflow-mlflow" --log-stream-name "<STREAM>" --region us-east-1

# Logs do Webapp
aws logs get-log-events --log-group-name "/ecs/hm-mlflow-webapp" --log-stream-name "<STREAM>" --region us-east-1

# Logs do treinamento
aws logs get-log-events --log-group-name "/ecs/hm-mlflow-model-training" --log-stream-name "<STREAM>" --region us-east-1
```

### Teste dos Servi√ßos
```bash
# Teste MLflow
curl -H "Host: mlflow.hm-mlflow.local" http://<ALB_DNS>

# Teste Webapp
curl -H "Host: app.hm-mlflow.local" http://<ALB_DNS>
```

## üîß Configura√ß√£o

### Vari√°veis de Ambiente (.env)
```bash
EXECUTION_ENVIRONMENT=local  # ou "cloud"
MLFLOW_TRACKING_URI_CLOUD=http://mlflow.hm-mlflow.local
AWS_ACCESS_KEY_ID=<sua_key>
AWS_SECRET_ACCESS_KEY=<sua_secret>
```

### Notebook Configuration
- **Local**: `PROFILE = "local"`
- **Cloud**: `PROFILE = "cloud"`

## üìÅ Estrutura do Projeto

```
HM-mlflow/
‚îú‚îÄ‚îÄ infra/              # Terraform (AWS)
‚îú‚îÄ‚îÄ mlflow/             # MLflow server
‚îú‚îÄ‚îÄ webapp/             # Interface web
‚îú‚îÄ‚îÄ model/              # Scripts de treinamento
‚îú‚îÄ‚îÄ minio/              # Scripts de cria√ß√£o do bucket S3 local
‚îú‚îÄ‚îÄ jupyter/            # Notebooks
‚îú‚îÄ‚îÄ source/             # Dados de treinamento
‚îú‚îÄ‚îÄ docker-compose.yaml # Orquestra√ß√£o local
‚îî‚îÄ‚îÄ README.md
```

## üõ†Ô∏è Tecnologias

- **MLflow**: Tracking e registro de modelos
- **FastAPI**: API do webapp
- **Scikit-learn**: Machine learning
- **OpenCV**: Processamento de imagens
- **Docker**: Containeriza√ß√£o
- **Terraform**: Infrastructure as Code
- **AWS**: ECS, S3, SageMaker, ALB
- **MinIO**: S3 local para desenvolvimento

## üìù Notas Importantes

- O notebook suporta execu√ß√£o local e na nuvem com a mesma base de c√≥digo
- Modelos s√£o automaticamente promovidos para "Production" ap√≥s treinamento
- O webapp sempre usa o modelo mais recente em produ√ß√£o
- DNS local √© necess√°rio para acessar servi√ßos na nuvem
- SageMaker configura DNS automaticamente quando `PROFILE = "cloud"`

## üîç Troubleshooting

### Problema: MLflow n√£o acess√≠vel na nuvem
**Solu√ß√£o**: Verifique se o DNS est√° configurado corretamente no arquivo hosts

### Problema: Imagens n√£o carregam
**Solu√ß√£o**: Verifique se os dados est√£o no bucket S3 correto

### Problema: Erro de permiss√£o no SageMaker
**Solu√ß√£o**: Verifique se a IAM role tem permiss√µes para S3 e MLflow

